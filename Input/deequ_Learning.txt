spark-shell --packages com.amazon.deequ:deequ:1.0.2,io.delta:delta-core_2.11:0.5.0

val df=spark.read.format("delta").load("/user/raptor/testing/hadoop/deltaTableTestFolder/outputFiles/carDetailTable_Silver/")

import com.amazon.deequ.analyzers.runners.{AnalysisRunner, AnalyzerContext}
import com.amazon.deequ.analyzers.runners.AnalyzerContext.successMetricsAsDataFrame
import com.amazon.deequ.analyzers.{Compliance, Correlation, Size, Completeness, Mean, ApproxCountDistinct,Entropy}


val analysisContextForResult = AnalysisRunner.onData(df) // gives analyser runner

val analysisRunnerAddedWithAnalyzer= analysisContextForResult.addAnalyzer(Size()).addAnalyzer(Completeness("Vehicle_id")).addAnalyzer(ApproxCountDistinct("Vehicle_id")) .addAnalyzer(Mean("miles")).addAnalyzer(Compliance("top miles", "miles >= 4000")).addAnalyzer(Correlation("model", "brand")).addAnalyzer(Correlation("miles", "number_of_owners")).addAnalyzer(Correlation("miles", "year")).addAnalyzer(Correlation("miles", "brand")) // give the stats you want

val analysisRunnerAddedWithAnalyzer= analysisContextForResult.addAnalyzer(Size()).addAnalyzer(Completeness("Vehicle_id")).addAnalyzer(ApproxCountDistinct("Vehicle_id")).addAnalyzer(Correlation("model", "number_of_owners")).addAnalyzer(Mean("miles")).addAnalyzer(Compliance("top model", "miles >= 4000")).addAnalyzer(Correlation("miles", "number_of_owners")).addAnalyzer(Correlation("miles", "year")).addAnalyzer(Correlation("miles", "brand")).addAnalyzer(Entropy("model")) // give the stats you want


val analysisContextResult = analysisRunnerAddedWithAnalyzer.run()
val metrics = successMetricsAsDataFrame(spark, analysisContextResult)

//val analysisRunnerAddedWithAnalyzer= analysisContextForResult.addAnalyzer(Size()).addAnalyzer(Completeness("Vehicle_id")).addAnalyzer(ApproxCountDistinct("Vehicle_id")) .addAnalyzer(Mean("miles")).addAnalyzer(Compliance("top miles", "miles >= 4000")).addAnalyzer(Correlation("miles", "number_of_owners")).addAnalyzer(Correlation("miles", "year"))// correlation works on numbers only
+-----------+----------------------+-------------------+-------------------+
|entity     |instance              |name               |value              |
+-----------+----------------------+-------------------+-------------------+
|Column     |Vehicle_id            |Completeness       |1.0                |
|Column     |Vehicle_id            |ApproxCountDistinct|66.0               |
|Dataset    |*                     |Size               |83.0               |
|Mutlicolumn|miles,number_of_owners|Correlation        |0.09298152399321875|
|Column     |top miles             |Compliance         |0.6746987951807228 |
|Column     |miles                 |Mean               |13024.096385542169 |
|Mutlicolumn|miles,year            |Correlation        |0.1753705776043787 |
+-----------+----------------------+-------------------+-------------------+

* vehicle id column has no empty column
* approximatelly 66 distinct vehicle id's are present
* count of df is 83 
* Correlation between miles and number_of_owners is very less. (-ve means not corellatd at all)
* Correlation between miles and year is very 10%. (-ve means not corellatd at all)
* avg of miles is 13024.096385542169

/*
val analysisResult: AnalyzerContext = { AnalysisRunner
  // data to run the analysis on
  .onData(dataset)
  // define analyzers that compute metrics
  .addAnalyzer(Size())
  .addAnalyzer(Completeness("review_id"))
  .addAnalyzer(ApproxCountDistinct("review_id"))
  .addAnalyzer(Mean("star_rating"))
  .addAnalyzer(Compliance("top star_rating", "star_rating >= 4.0"))
  .addAnalyzer(Correlation("total_votes", "star_rating"))
  .addAnalyzer(Correlation("total_votes", "helpful_votes"))
  // compute metrics
  .run()
}

val metrics = successMetricsAsDataFrame(spark, analysisResult)

*/


// -------------------------------------------------------- next defining test suite's

import com.amazon.deequ.{VerificationSuite, VerificationResult}
import com.amazon.deequ.VerificationResult.checkResultsAsDataFrame
import com.amazon.deequ.checks.{Check, CheckLevel}

val verificationSuiteWithDfPassed= VerificationSuite().onData(df)
val verificationSuiteWithDfPassedAndCheckerAdded=verificationSuiteWithDfPassed.addCheck(Check(CheckLevel.Error, "Review Check").hasSize(_ >= 3000000).hasMin("miles", _ == 100).hasMax("miles", _ == 5000).isComplete("Vehicle_id").isUnique("Vehicle_id").isContainedIn("number_of_owners",Array("2","3","4")).isComplete("month").isContainedIn("brand", Array("Lambhorghini", "Konegzegg", "Ferrari", "Pagani", "Jeep")).isNonNegative("year"))

val analysisContextResult = verificationSuiteWithDfPassedAndCheckerAdded.run()
val resultDataFrame  = checkResultsAsDataFrame(spark, analysisContextResult) // creates result as a data frame

/*


size check failed less records
miles minimum is in 1000's
miles maximum is in 67000's
vehicle id is complete
Vehicle_id is unique
month is complete
brand has more values than ("Lambhorghini", "Konegzegg", "Ferrari", "Pagani", "Jeep") , so failed
year is non negative



+------------+-----------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------------------------------------------+
|check       |check_level|check_status|constraint                                                                                                                                                                               |constraint_status|constraint_message                                                 |
+------------+-----------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------------------------------------------+
|Review Check|Error      |Error       |SizeConstraint(Size(None))                                                                                                                                                               |Failure          |Value: 83 does not meet the constraint requirement!                |
|Review Check|Error      |Error       |MinimumConstraint(Minimum(miles,None))                                                                                                                                                   |Failure          |Value: 1000.0 does not meet the constraint requirement!            |
|Review Check|Error      |Error       |MaximumConstraint(Maximum(miles,None))                                                                                                                                                   |Failure          |Value: 67000.0 does not meet the constraint requirement!           |
|Review Check|Error      |Error       |CompletenessConstraint(Completeness(Vehicle_id,None))                                                                                                                                    |Success          |                                                                   |
|Review Check|Error      |Error       |UniquenessConstraint(Uniqueness(List(Vehicle_id)))                                                                                                                                       |Failure          |Value: 0.6385542168674698 does not meet the constraint requirement!|
|Review Check|Error      |Error       |CompletenessConstraint(Completeness(month,None))                                                                                                                                         |Success          |                                                                   |
|Review Check|Error      |Error       |ComplianceConstraint(Compliance(brand contained in Lambhorghini,Konegzegg,Ferrari,Pagani,Jeep,`brand` IS NULL OR `brand` IN ('Lambhorghini','Konegzegg','Ferrari','Pagani','Jeep'),None))|Failure          |Value: 0.4457831325301205 does not meet the constraint requirement!|
|Review Check|Error      |Error       |ComplianceConstraint(Compliance(year is non-negative,COALESCE(year, 0.0) >= 0,None))                                                                                                     |Success          |                                                                   |
+------------+-----------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+-------------------------------------------------------------------+

*/

/*

Result explanation.

*df count is less than 3000000
*Minimum value for miles is not 100
*Maximum value for miles is not 5000
*Vehicle_id has no null's or is not empty
*Vehicle_id is unique
*number_of_owners has values other than "2","3","4"
*month has no null's or is not empty
*brand has values other than "Lambhorghini", "Konegzegg", "Ferrari", "Pagani", "Jeep"
*year has no -ve values


+------------+
|       brand|
+------------+
|   Volswogen|
|Lambhorghini|
|        Jeep|
|     Hyundai|
|   Konegzegg|
|     Renault|
|      Pagani|
|         BAC|
|     Ferrari|
|Aston-Martin|
|        Ford|
|     Bugatti|
+------------+



val verificationResult: VerificationResult = { VerificationSuite()
  // data to run the verification on
  .onData(dataset)
  // define a data quality check
  .addCheck(
    Check(CheckLevel.Error, "Review Check") 
      .hasSize(_ >= 3000000) // at least 3 million rows
      .hasMin("star_rating", _ == 1.0) // min is 1.0
      .hasMax("star_rating", _ == 5.0) // max is 5.0
      .isComplete("review_id") // should never be NULL
      .isUnique("review_id") // should not contain duplicates
      .isComplete("marketplace") // should never be NULL
      // contains only the listed values
      .isContainedIn("marketplace", Array("US", "UK", "DE", "JP", "FR"))
      .isNonNegative("year")) // should not contain negative values
  // compute metrics and verify check conditions
  .run()
}

// convert check results to a Spark data frame
val resultDataFrame = checkResultsAsDataFrame(spark, verificationResult)
*/


---------- constraint suggestion


import com.amazon.deequ.suggestions.{ConstraintSuggestionRunner, Rules}
import spark.implicits._ //for toDF

val suggestionResult =ConstraintSuggestionRunner().onData(df).addConstraintRules(Rules.DEFAULT).run()

val suggestionDataFrame = suggestionResult.constraintSuggestions.flatMap{ case (column, suggestions) =>  suggestions.map ( constraint =>  (column, constraint.description, constraint.codeForConstraint) )}.toSeq.toDF("columnName","constraintDescription","codeForConstraintImpementation")

/*

val suggestionResult = { ConstraintSuggestionRunner()
  // data to suggest constraints for
  .onData(dataset)
  // default set of rules for constraint suggestion
  .addConstraintRules(Rules.DEFAULT)
  // run data profiling and constraint suggestion
  .run()
}

// We can now investigate the constraints that Deequ suggested. 
val suggestionDataFrame = suggestionResult.constraintSuggestions.flatMap { 
  case (column, suggestions) => 
    suggestions.map { constraint =>
      (column, constraint.description, constraint.codeForConstraint)
    } 
}.toSeq.toDS()

*/


