Run a producer from 2.4.4 spark kafka push datato producer script's.

readextractload sh. triggres the sparksubmit to read from kafka producer and push it to delta table.

readdelta/stream sh. triggres the sparksubmit to read from delta table which is being fed every five second by the previous stream producer job and  display's it in console as of now. more things can be done to save that data and crunch it.
